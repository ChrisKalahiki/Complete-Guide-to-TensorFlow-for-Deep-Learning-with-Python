{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Exercise \n",
    "\n",
    "California Housing Data\n",
    "\n",
    "This data set contains information about all the block groups in California from the 1990 Census. In this sample a block group on average includes 1425.5 individuals living in a geographically compact area. \n",
    "\n",
    "The task is to aproximate the median house value of each block from the values of the rest of the variables. \n",
    "\n",
    " It has been obtained from the LIACC repository. The original page where the data set can be found is: http://www.liaad.up.pt/~ltorgo/Regression/DataSets.html.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The Features:\n",
    " \n",
    "* housingMedianAge: continuous. \n",
    "* totalRooms: continuous. \n",
    "* totalBedrooms: continuous. \n",
    "* population: continuous. \n",
    "* households: continuous. \n",
    "* medianIncome: continuous. \n",
    "* medianHouseValue: continuous. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import the cal_housing_clean.csv file with pandas. Separate it into a training (70%) and testing set(30%).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv('/home/pacho/Documentos/Elearning/Udemy/Tensorflow-Bootcamp-master/02-TensorFlow-Basics/cal_housing_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "      <th>medianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   housingMedianAge  totalRooms  totalBedrooms  population  households  \\\n",
       "0              41.0       880.0          129.0       322.0       126.0   \n",
       "1              21.0      7099.0         1106.0      2401.0      1138.0   \n",
       "2              52.0      1467.0          190.0       496.0       177.0   \n",
       "3              52.0      1274.0          235.0       558.0       219.0   \n",
       "4              52.0      1627.0          280.0       565.0       259.0   \n",
       "\n",
       "   medianIncome  medianHouseValue  \n",
       "0        8.3252          452600.0  \n",
       "1        8.3014          358500.0  \n",
       "2        7.2574          352100.0  \n",
       "3        5.6431          341300.0  \n",
       "4        3.8462          342200.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['housingMedianAge', 'totalRooms', 'totalBedrooms', 'population',\n",
       "       'households', 'medianIncome', 'medianHouseValue'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>housingMedianAge</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>37.00000</td>\n",
       "      <td>52.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalRooms</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1447.7500</td>\n",
       "      <td>2127.0000</td>\n",
       "      <td>3148.00000</td>\n",
       "      <td>39320.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalBedrooms</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>537.898014</td>\n",
       "      <td>421.247906</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>295.0000</td>\n",
       "      <td>435.0000</td>\n",
       "      <td>647.00000</td>\n",
       "      <td>6445.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>787.0000</td>\n",
       "      <td>1166.0000</td>\n",
       "      <td>1725.00000</td>\n",
       "      <td>35682.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>households</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>499.539680</td>\n",
       "      <td>382.329753</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>280.0000</td>\n",
       "      <td>409.0000</td>\n",
       "      <td>605.00000</td>\n",
       "      <td>6082.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medianIncome</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>3.870671</td>\n",
       "      <td>1.899822</td>\n",
       "      <td>0.4999</td>\n",
       "      <td>2.5634</td>\n",
       "      <td>3.5348</td>\n",
       "      <td>4.74325</td>\n",
       "      <td>15.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medianHouseValue</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>206855.816909</td>\n",
       "      <td>115395.615874</td>\n",
       "      <td>14999.0000</td>\n",
       "      <td>119600.0000</td>\n",
       "      <td>179700.0000</td>\n",
       "      <td>264725.00000</td>\n",
       "      <td>500001.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count           mean            std         min  \\\n",
       "housingMedianAge  20640.0      28.639486      12.585558      1.0000   \n",
       "totalRooms        20640.0    2635.763081    2181.615252      2.0000   \n",
       "totalBedrooms     20640.0     537.898014     421.247906      1.0000   \n",
       "population        20640.0    1425.476744    1132.462122      3.0000   \n",
       "households        20640.0     499.539680     382.329753      1.0000   \n",
       "medianIncome      20640.0       3.870671       1.899822      0.4999   \n",
       "medianHouseValue  20640.0  206855.816909  115395.615874  14999.0000   \n",
       "\n",
       "                          25%          50%           75%          max  \n",
       "housingMedianAge      18.0000      29.0000      37.00000      52.0000  \n",
       "totalRooms          1447.7500    2127.0000    3148.00000   39320.0000  \n",
       "totalBedrooms        295.0000     435.0000     647.00000    6445.0000  \n",
       "population           787.0000    1166.0000    1725.00000   35682.0000  \n",
       "households           280.0000     409.0000     605.00000    6082.0000  \n",
       "medianIncome           2.5634       3.5348       4.74325      15.0001  \n",
       "medianHouseValue  119600.0000  179700.0000  264725.00000  500001.0000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = housing[['housingMedianAge', 'totalRooms', 'totalBedrooms', 'population',\n",
    "       'households', 'medianIncome']]\n",
    "y_data = housing['medianHouseValue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_data,y_data,test_size=0.3, random_state = 101)\n",
    "index_x_train = X_train.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the Feature Data\n",
    "\n",
    "** Use sklearn preprocessing to create a MinMaxScaler for the feature data. Fit this scaler only to the training data. Then use it to transform X_test and X_train. Then use the scaled X_test and X_train along with pd.Dataframe to re-create two dataframes of scaled data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(copy=True, feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns)\n",
    "X_train.index = index_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Columns\n",
    "\n",
    "** Create the necessary tf.feature_column objects for the estimator. They should all be trated as continuous numeric_columns. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['housingMedianAge', 'totalRooms', 'totalBedrooms', 'population',\n",
       "       'households', 'medianIncome', 'medianHouseValue'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['housingMedianAge', 'totalRooms', 'totalBedrooms', 'population',\n",
       "       'households', 'medianIncome'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.columns.values[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [tf.feature_column.numeric_column(x) for x in housing.columns.values[:-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the input function for the estimator object. (play around with batch_size and num_epochs)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(x=X_train, y=y_train, batch_size=10, num_epochs=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the estimator model. Use a DNNRegressor. Play around with the hidden units! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpvpeu1er2\n",
      "INFO:tensorflow:Using config: {'_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7feb1e5fc2e8>, '_task_id': 0, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_task_type': 'worker', '_is_chief': True, '_keep_checkpoint_max': 5, '_num_worker_replicas': 1, '_service': None, '_model_dir': '/tmp/tmpvpeu1er2', '_session_config': None, '_save_summary_steps': 100, '_tf_random_seed': None, '_master': '', '_num_ps_replicas': 0, '_log_step_count_steps': 100, '_keep_checkpoint_every_n_hours': 10000}\n"
     ]
    }
   ],
   "source": [
    "dnn_model = tf.estimator.DNNRegressor(hidden_units=[10,10,10],feature_columns=feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ** Train the model for ~1,000 steps. (Later come back to this and train it for more and check for improvement) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpvpeu1er2/model.ckpt-10000\n",
      "INFO:tensorflow:Saving checkpoints for 10001 into /tmp/tmpvpeu1er2/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.07281e+11, step = 10001\n",
      "INFO:tensorflow:global_step/sec: 720.842\n",
      "INFO:tensorflow:loss = 8.28651e+10, step = 10101 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 902.255\n",
      "INFO:tensorflow:loss = 4.4921e+10, step = 10201 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 830.83\n",
      "INFO:tensorflow:loss = 1.21256e+11, step = 10301 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 895.769\n",
      "INFO:tensorflow:loss = 1.1754e+11, step = 10401 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 854.554\n",
      "INFO:tensorflow:loss = 7.13637e+10, step = 10501 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 862.827\n",
      "INFO:tensorflow:loss = 1.25413e+11, step = 10601 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 859.388\n",
      "INFO:tensorflow:loss = 1.88404e+11, step = 10701 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 792.338\n",
      "INFO:tensorflow:loss = 6.82469e+10, step = 10801 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 882.365\n",
      "INFO:tensorflow:loss = 6.97764e+10, step = 10901 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 837.011\n",
      "INFO:tensorflow:loss = 1.52664e+11, step = 11001 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 844.662\n",
      "INFO:tensorflow:loss = 4.5943e+10, step = 11101 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 894.764\n",
      "INFO:tensorflow:loss = 1.31054e+11, step = 11201 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 839.564\n",
      "INFO:tensorflow:loss = 5.05722e+10, step = 11301 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 785.556\n",
      "INFO:tensorflow:loss = 6.57985e+10, step = 11401 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 823.065\n",
      "INFO:tensorflow:loss = 9.47296e+10, step = 11501 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 872.365\n",
      "INFO:tensorflow:loss = 5.80218e+10, step = 11601 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 878.65\n",
      "INFO:tensorflow:loss = 1.40956e+11, step = 11701 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 845.426\n",
      "INFO:tensorflow:loss = 8.07288e+10, step = 11801 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 925.917\n",
      "INFO:tensorflow:loss = 1.32159e+11, step = 11901 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 829.404\n",
      "INFO:tensorflow:loss = 1.30652e+11, step = 12001 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 868.922\n",
      "INFO:tensorflow:loss = 8.2456e+10, step = 12101 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 719.641\n",
      "INFO:tensorflow:loss = 5.01501e+10, step = 12201 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 825.015\n",
      "INFO:tensorflow:loss = 1.76404e+11, step = 12301 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 716.456\n",
      "INFO:tensorflow:loss = 6.4591e+10, step = 12401 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 811.978\n",
      "INFO:tensorflow:loss = 5.21307e+10, step = 12501 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 862.944\n",
      "INFO:tensorflow:loss = 1.15116e+11, step = 12601 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 877.503\n",
      "INFO:tensorflow:loss = 1.4396e+11, step = 12701 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 831.453\n",
      "INFO:tensorflow:loss = 7.36413e+10, step = 12801 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 918.563\n",
      "INFO:tensorflow:loss = 6.46978e+10, step = 12901 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 736.266\n",
      "INFO:tensorflow:loss = 8.07441e+10, step = 13001 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 763.993\n",
      "INFO:tensorflow:loss = 6.34086e+10, step = 13101 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 892.162\n",
      "INFO:tensorflow:loss = 1.43742e+11, step = 13201 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 811.062\n",
      "INFO:tensorflow:loss = 1.05904e+11, step = 13301 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 767.483\n",
      "INFO:tensorflow:loss = 1.85467e+11, step = 13401 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 958.297\n",
      "INFO:tensorflow:loss = 1.56452e+11, step = 13501 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 948.345\n",
      "INFO:tensorflow:loss = 3.64475e+10, step = 13601 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 975.914\n",
      "INFO:tensorflow:loss = 1.46309e+11, step = 13701 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 933.324\n",
      "INFO:tensorflow:loss = 1.79279e+11, step = 13801 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 912.047\n",
      "INFO:tensorflow:loss = 1.89896e+11, step = 13901 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 886.299\n",
      "INFO:tensorflow:loss = 1.79916e+11, step = 14001 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 890.106\n",
      "INFO:tensorflow:loss = 9.80181e+10, step = 14101 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 843.154\n",
      "INFO:tensorflow:loss = 8.13103e+10, step = 14201 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 834.872\n",
      "INFO:tensorflow:loss = 8.13246e+10, step = 14301 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 640.325\n",
      "INFO:tensorflow:loss = 1.39092e+11, step = 14401 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 688.508\n",
      "INFO:tensorflow:loss = 1.53969e+11, step = 14501 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 1016.77\n",
      "INFO:tensorflow:loss = 5.88145e+10, step = 14601 (0.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 825.665\n",
      "INFO:tensorflow:loss = 6.55084e+10, step = 14701 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 679.939\n",
      "INFO:tensorflow:loss = 3.32669e+10, step = 14801 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 960.941\n",
      "INFO:tensorflow:loss = 1.38933e+11, step = 14901 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 933.148\n",
      "INFO:tensorflow:loss = 3.01107e+10, step = 15001 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 920.698\n",
      "INFO:tensorflow:loss = 1.50572e+11, step = 15101 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 924.548\n",
      "INFO:tensorflow:loss = 7.08379e+10, step = 15201 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 834.305\n",
      "INFO:tensorflow:loss = 8.17309e+10, step = 15301 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 899.376\n",
      "INFO:tensorflow:loss = 1.18884e+11, step = 15401 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 1017.63\n",
      "INFO:tensorflow:loss = 2.16438e+11, step = 15501 (0.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 784.908\n",
      "INFO:tensorflow:loss = 7.74962e+10, step = 15601 (0.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 884.089\n",
      "INFO:tensorflow:loss = 8.09752e+10, step = 15701 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 887.954\n",
      "INFO:tensorflow:loss = 1.60193e+11, step = 15801 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 905.428\n",
      "INFO:tensorflow:loss = 5.09163e+10, step = 15901 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 722.676\n",
      "INFO:tensorflow:loss = 3.88288e+10, step = 16001 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 854.815\n",
      "INFO:tensorflow:loss = 4.35382e+10, step = 16101 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 857.936\n",
      "INFO:tensorflow:loss = 6.70974e+10, step = 16201 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 810.179\n",
      "INFO:tensorflow:loss = 9.41086e+10, step = 16301 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 746.44\n",
      "INFO:tensorflow:loss = 5.94591e+10, step = 16401 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 773.158\n",
      "INFO:tensorflow:loss = 2.37442e+11, step = 16501 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 913.806\n",
      "INFO:tensorflow:loss = 1.0601e+11, step = 16601 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 895.341\n",
      "INFO:tensorflow:loss = 6.16493e+10, step = 16701 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 878.486\n",
      "INFO:tensorflow:loss = 1.45165e+11, step = 16801 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 898.265\n",
      "INFO:tensorflow:loss = 9.55497e+10, step = 16901 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.607\n",
      "INFO:tensorflow:loss = 8.51523e+10, step = 17001 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 843.064\n",
      "INFO:tensorflow:loss = 1.15693e+11, step = 17101 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 827.241\n",
      "INFO:tensorflow:loss = 1.79892e+11, step = 17201 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 838.515\n",
      "INFO:tensorflow:loss = 1.14559e+11, step = 17301 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 886.219\n",
      "INFO:tensorflow:loss = 4.90254e+10, step = 17401 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 864.032\n",
      "INFO:tensorflow:loss = 3.26243e+10, step = 17501 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 914.597\n",
      "INFO:tensorflow:loss = 4.63117e+10, step = 17601 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 813.168\n",
      "INFO:tensorflow:loss = 6.96114e+10, step = 17701 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.247\n",
      "INFO:tensorflow:loss = 1.11689e+11, step = 17801 (0.119 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 865.649\n",
      "INFO:tensorflow:loss = 5.08626e+10, step = 17901 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 875.223\n",
      "INFO:tensorflow:loss = 5.00312e+10, step = 18001 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 857.794\n",
      "INFO:tensorflow:loss = 1.87069e+11, step = 18101 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 874.012\n",
      "INFO:tensorflow:loss = 1.50998e+11, step = 18201 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 869.125\n",
      "INFO:tensorflow:loss = 4.00568e+10, step = 18301 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 939.447\n",
      "INFO:tensorflow:loss = 9.58145e+10, step = 18401 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 861.774\n",
      "INFO:tensorflow:loss = 1.41718e+11, step = 18501 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 856.117\n",
      "INFO:tensorflow:loss = 6.73572e+10, step = 18601 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 936.984\n",
      "INFO:tensorflow:loss = 1.15598e+11, step = 18701 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 888.411\n",
      "INFO:tensorflow:loss = 9.28128e+10, step = 18801 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 907.832\n",
      "INFO:tensorflow:loss = 8.21555e+10, step = 18901 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 901.02\n",
      "INFO:tensorflow:loss = 4.19621e+10, step = 19001 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 891.093\n",
      "INFO:tensorflow:loss = 5.4446e+10, step = 19101 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 896.374\n",
      "INFO:tensorflow:loss = 1.02722e+11, step = 19201 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 993.487\n",
      "INFO:tensorflow:loss = 1.04022e+11, step = 19301 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 870.397\n",
      "INFO:tensorflow:loss = 1.44555e+11, step = 19401 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 828.755\n",
      "INFO:tensorflow:loss = 1.92032e+10, step = 19501 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 838.214\n",
      "INFO:tensorflow:loss = 1.5867e+11, step = 19601 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 938.086\n",
      "INFO:tensorflow:loss = 1.18219e+11, step = 19701 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 859.802\n",
      "INFO:tensorflow:loss = 3.71892e+10, step = 19801 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 769.497\n",
      "INFO:tensorflow:loss = 5.63013e+10, step = 19901 (0.133 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into /tmp/tmpvpeu1er2/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.55686e+11.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNRegressor at 0x7feb32261630>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_model.train(input_fn=input_func,steps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a prediction input function and then use the .predict method off your estimator model to create a list or predictions on your test data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_input_func = tf.estimator.inputs.pandas_input_fn(x=X_test, batch_size=10, num_epochs=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = dnn_model.predict(pred_input_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmpvpeu1er2/model.ckpt-20000\n"
     ]
    }
   ],
   "source": [
    "predictions = [pred['predictions'] for pred in preds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Calculate the RMSE. You should be able to get around 100,000 RMSE (remember that this is in the same units as the label.) Do this manually or use [sklearn.metrics](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97964.60188306686"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(mean_squared_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
